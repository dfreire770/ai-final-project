{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfreire770/dq-ddq-smb-agent/blob/main/mario-rl-video-episodes_added_check_point_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zR5l7a-sPne",
        "outputId": "54523542-dd86-46cd-96ac-98433e3b8d84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/721.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/721.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827619 sha256=a344346fae993482009bf18bb75eadc3f777b458bdd3089ac0c742b183458839\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n",
            "Requirement already satisfied: gym-notices==0.0.8 in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Collecting gymnasium==0.29.1\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d105f7d4f10>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/a8/4d/3cbfd81ed84db450dbe73a89afcd8bc405273918415649ac6683356afe92/gymnasium-0.29.1-py3-none-any.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting gym-super-mario-bros==7.4.0\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nes-py>=8.1.4 (from gym-super-mario-bros==7.4.0)\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (1.25.2)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.0.8)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535717 sha256=2e022097f1074537fe98328188b2bbfa4107aaa10313bb1b8df71b0429c41990\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n",
            "Successfully built nes-py\n",
            "Installing collected packages: pyglet, nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.4.0 nes-py-8.2.1 pyglet-1.5.21\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,069 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,798 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,374 kB]\n",
            "Fetched 7,542 kB in 2s (3,556 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev\n",
            "  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libice-dev libopengl-dev libsm-dev libxfont2 libxkbfile1\n",
            "  libxt-dev x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev libxfont2\n",
            "  libxkbfile1 libxt-dev x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 25 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 9,075 kB of archives.\n",
            "After this operation, 18.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 9,075 kB in 1s (9,051 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 25.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../19-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../20-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../21-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../22-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../23-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../24-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.26.2\n",
        "!pip install gym-notices==0.0.8\n",
        "!pip install gymnasium==0.29.1\n",
        "!pip install gym-super-mario-bros==7.4.0\n",
        "!pip install moviepy\n",
        "#!pip install ffmpeg-python==0.2.0\n",
        "\n",
        "#!pip install gym-super-mario-bros\n",
        "!pip --disable-pip-version-check install -q nes_py\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip --disable-pip-version-check install -q pyvirtualdisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaPSChcvtav4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "\n",
        "import time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# change directory\n",
        "import os\n",
        "#os.chdir('/kaggle/input/gym-super-mario-bros'). <-- MAY NEED CHANGE HERE\n",
        "\n",
        "# install controller\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation\n",
        "\n",
        "#from pyvirtualdisplay import Display\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "\n",
        "#from gym.wrappers import Monitor -- DEPRECATED\n",
        "#from gym.wrappers.record_video import RecordVideo\n",
        "from glob import glob\n",
        "\n",
        "import base64\n",
        "import io\n",
        "\n",
        "import cv2\n",
        "\n",
        "from time import sleep\n",
        "\n",
        "#from gym_recorder import Recorder\n",
        "\n",
        "#display = Display(visible=0, size=(600, 300))\n",
        "#display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AyLSER7txfs"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import torch\n",
        "import random, datetime, numpy as np\n",
        "from skimage import transform\n",
        "\n",
        "from gym.spaces import Box\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        resize_obs = transform.resize(observation, self.shape)\n",
        "        # cast float back to uint8\n",
        "        resize_obs *= 255\n",
        "        resize_obs = resize_obs.astype(np.uint8)\n",
        "        return resize_obs\n",
        "\n",
        "\n",
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, truncated, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, truncated, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkikVdrpuFjN"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MarioNet(nn.Module):\n",
        "    \"\"\"\n",
        "        input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        c, w, h = input_dim\n",
        "\n",
        "        if h != 84: raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
        "        if w != 84: raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
        "\n",
        "        self.online = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "\n",
        "        self.target = copy.deepcopy(self.online)\n",
        "\n",
        "        # freeze Q-target parameters\n",
        "        for p in self.target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, input, model):\n",
        "        if model == \"online\":\n",
        "            return self.online(input)\n",
        "        elif model == \"target\":\n",
        "            return self.target(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnN1KDQWCAjB"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Mario:\n",
        "    def __init__(self, state_dim, action_dim, save_dir, checkpoint=None):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.memory = deque(maxlen=100000)\n",
        "        self.batch_size = 32\n",
        "\n",
        "        self.exploration_rate = 1\n",
        "        self.exploration_rate_decay = 0.99999975\n",
        "        self.exploration_rate_min = 0.1\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        self.curr_step = 0\n",
        "        self.burnin = 1e5  # min. experiences before training\n",
        "        self.learn_every = 3   # no. of experiences between updates to Q_online\n",
        "        self.sync_every = 1e4   # no. of experiences between Q_target & Q_online sync\n",
        "\n",
        "        #self.save_every = 5e5   # no. of experiences between saving Mario Net\n",
        "        #self.save_every = 100\n",
        "        self.save_every = 10000\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "\n",
        "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
        "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
        "        if self.use_cuda:\n",
        "            self.net = self.net.to(device='cuda')\n",
        "        if checkpoint:\n",
        "            self.load(checkpoint)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
        "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Given a state, choose an epsilon-greedy action and update value of step.\n",
        "\n",
        "        Inputs:\n",
        "        state(LazyFrame): A single observation of the current state, dimension is (state_dim)\n",
        "        Outputs:\n",
        "        action_idx (int): An integer representing which action Mario will perform\n",
        "        \"\"\"\n",
        "        # EXPLORE\n",
        "        if np.random.rand() < self.exploration_rate:\n",
        "            action_idx = np.random.randint(self.action_dim)\n",
        "\n",
        "        # EXPLOIT\n",
        "        else:\n",
        "            state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n",
        "            state = state.unsqueeze(0)\n",
        "            action_values = self.net(state, model='online')\n",
        "            action_idx = torch.argmax(action_values, axis=1).item()\n",
        "\n",
        "        # decrease exploration_rate\n",
        "        self.exploration_rate *= self.exploration_rate_decay\n",
        "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
        "\n",
        "        # increment step\n",
        "        self.curr_step += 1\n",
        "        return action_idx\n",
        "\n",
        "    def cache(self, state, next_state, action, reward, done):\n",
        "        \"\"\"\n",
        "        Store the experience to self.memory (replay buffer)\n",
        "\n",
        "        Inputs:\n",
        "        state (LazyFrame),\n",
        "        next_state (LazyFrame),\n",
        "        action (int),\n",
        "        reward (float),\n",
        "        done(bool))\n",
        "        \"\"\"\n",
        "        state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n",
        "        next_state = torch.FloatTensor(next_state).cuda() if self.use_cuda else torch.FloatTensor(next_state)\n",
        "        action = torch.LongTensor([action]).cuda() if self.use_cuda else torch.LongTensor([action])\n",
        "        reward = torch.DoubleTensor([reward]).cuda() if self.use_cuda else torch.DoubleTensor([reward])\n",
        "        done = torch.BoolTensor([done]).cuda() if self.use_cuda else torch.BoolTensor([done])\n",
        "\n",
        "        self.memory.append( (state, next_state, action, reward, done,) )\n",
        "\n",
        "\n",
        "    def recall(self):\n",
        "        \"\"\"\n",
        "        Retrieve a batch of experiences from memory\n",
        "        \"\"\"\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        state, next_state, action, reward, done = map(torch.stack, zip(*batch))\n",
        "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
        "\n",
        "\n",
        "    def td_estimate(self, state, action):\n",
        "        current_Q = self.net(state, model='online')[np.arange(0, self.batch_size), action] # Q_online(s,a)\n",
        "        return current_Q\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def td_target(self, reward, next_state, done):\n",
        "        next_state_Q = self.net(next_state, model='online')\n",
        "        best_action = torch.argmax(next_state_Q, axis=1)\n",
        "        next_Q = self.net(next_state, model='target')[np.arange(0, self.batch_size), best_action]\n",
        "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()\n",
        "\n",
        "\n",
        "    def update_Q_online(self, td_estimate, td_target) :\n",
        "        loss = self.loss_fn(td_estimate, td_target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def sync_Q_target(self):\n",
        "        self.net.target.load_state_dict(self.net.online.state_dict())\n",
        "\n",
        "\n",
        "    def learn(self):\n",
        "        if self.curr_step % self.sync_every == 0:\n",
        "            self.sync_Q_target()\n",
        "\n",
        "        if self.curr_step % self.save_every == 0:\n",
        "            self.save()\n",
        "\n",
        "        if self.curr_step < self.burnin:\n",
        "            return None, None\n",
        "\n",
        "        if self.curr_step % self.learn_every != 0:\n",
        "            return None, None\n",
        "\n",
        "        # Sample from memory\n",
        "        state, next_state, action, reward, done = self.recall()\n",
        "\n",
        "        # Get TD Estimate\n",
        "        td_est = self.td_estimate(state, action)\n",
        "\n",
        "        # Get TD Target\n",
        "        td_tgt = self.td_target(reward, next_state, done)\n",
        "\n",
        "        # Backpropagate loss through Q_online\n",
        "        loss = self.update_Q_online(td_est, td_tgt)\n",
        "\n",
        "        return (td_est.mean().item(), loss)\n",
        "\n",
        "\n",
        "    def save(self):\n",
        "        save_path = self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
        "        torch.save(\n",
        "            dict(\n",
        "                model=self.net.state_dict(),\n",
        "                exploration_rate=self.exploration_rate\n",
        "            ),\n",
        "            save_path\n",
        "        )\n",
        "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
        "\n",
        "\n",
        "    def load(self, load_path):\n",
        "        if not load_path.exists():\n",
        "            raise ValueError(f\"{load_path} does not exist\")\n",
        "\n",
        "        ckp = torch.load(load_path, map_location=('cuda' if self.use_cuda else 'cpu'))\n",
        "        exploration_rate = ckp.get('exploration_rate')\n",
        "        state_dict = ckp.get('model')\n",
        "\n",
        "        print(f\"Loading model at {load_path} with exploration rate {exploration_rate}\")\n",
        "        self.net.load_state_dict(state_dict)\n",
        "        self.exploration_rate = exploration_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMG3hp_LuOsi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class MetricLogger():\n",
        "    def __init__(self, save_dir):\n",
        "        self.save_log = save_dir / \"log\"\n",
        "        with open(self.save_log, \"w\") as f:\n",
        "            f.write(\n",
        "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
        "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
        "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
        "            )\n",
        "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
        "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
        "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
        "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
        "\n",
        "        # History metrics\n",
        "        self.ep_rewards = []\n",
        "        self.ep_lengths = []\n",
        "        self.ep_avg_losses = []\n",
        "        self.ep_avg_qs = []\n",
        "\n",
        "        # Moving averages, added for every call to record()\n",
        "        self.moving_avg_ep_rewards = []\n",
        "        self.moving_avg_ep_lengths = []\n",
        "        self.moving_avg_ep_avg_losses = []\n",
        "        self.moving_avg_ep_avg_qs = []\n",
        "\n",
        "        # Current episode metric\n",
        "        self.init_episode()\n",
        "\n",
        "        # Timing\n",
        "        self.record_time = time.time()\n",
        "\n",
        "\n",
        "    def log_step(self, reward, loss, q):\n",
        "        self.curr_ep_reward += reward\n",
        "        self.curr_ep_length += 1\n",
        "        if loss:\n",
        "            self.curr_ep_loss += loss\n",
        "            self.curr_ep_q += q\n",
        "            self.curr_ep_loss_length += 1\n",
        "\n",
        "    def log_episode(self):\n",
        "        \"Mark end of episode\"\n",
        "        self.ep_rewards.append(self.curr_ep_reward)\n",
        "        self.ep_lengths.append(self.curr_ep_length)\n",
        "        if self.curr_ep_loss_length == 0:\n",
        "            ep_avg_loss = 0\n",
        "            ep_avg_q = 0\n",
        "        else:\n",
        "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
        "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
        "        self.ep_avg_losses.append(ep_avg_loss)\n",
        "        self.ep_avg_qs.append(ep_avg_q)\n",
        "\n",
        "        self.init_episode()\n",
        "\n",
        "    def init_episode(self):\n",
        "        self.curr_ep_reward = 0.0\n",
        "        self.curr_ep_length = 0\n",
        "        self.curr_ep_loss = 0.0\n",
        "        self.curr_ep_q = 0.0\n",
        "        self.curr_ep_loss_length = 0\n",
        "\n",
        "    def record(self, episode, epsilon, step):\n",
        "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
        "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
        "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
        "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
        "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
        "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
        "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
        "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
        "\n",
        "\n",
        "        last_record_time = self.record_time\n",
        "        self.record_time = time.time()\n",
        "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
        "\n",
        "        print(\n",
        "            f\"Episode {episode} - \"\n",
        "            f\"Step {step} - \"\n",
        "            f\"Epsilon {epsilon} - \"\n",
        "            f\"Mean Reward {mean_ep_reward} - \"\n",
        "            f\"Mean Length {mean_ep_length} - \"\n",
        "            f\"Mean Loss {mean_ep_loss} - \"\n",
        "            f\"Mean Q Value {mean_ep_q} - \"\n",
        "            f\"Time Delta {time_since_last_record} - \"\n",
        "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
        "        )\n",
        "\n",
        "        with open(self.save_log, \"a\") as f:\n",
        "            f.write(\n",
        "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
        "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
        "                f\"{time_since_last_record:15.3f}\"\n",
        "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
        "            )\n",
        "\n",
        "        for metric in [\"ep_rewards\", \"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\"]:\n",
        "            plt.plot(getattr(self, f\"moving_avg_{metric}\"))\n",
        "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n",
        "            plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_recent_checkpoint(path):\n",
        "\n",
        "  if os.path.exists(path):\n",
        "    # Get a list of all files in the directory\n",
        "    file_list = []\n",
        "    for file in glob(f'{path}/*/*.chkpt'):\n",
        "      file_list.append(file)\n",
        "    file_list.sort(key=os.path.getmtime)\n",
        "    if len(file_list) > 0:\n",
        "      return file_list[-1]\n",
        "    else:\n",
        "      return None\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "Total_num_training_episodes = 0\n",
        "# initial number of total episodes training"
      ],
      "metadata": {
        "id": "YViGcbSrQOgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjzuPvNkuVbk",
        "outputId": "9a029eff-1d4c-406a-d8c1-b8a81666ac16"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "No checkpoint found - starting training from zero.\n",
            "\n",
            "Total number of training episodes 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "<ipython-input-5-3dfa345d5c3b>:75: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 - Step 111 - Epsilon 0.9999722503815551 - Mean Reward 615.0 - Mean Length 111.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 2.589 - Time 2024-05-13T17:02:40\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_1.chkpt at step 10000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_2.chkpt at step 20000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_3.chkpt at step 30000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_4.chkpt at step 40000\n",
            "Episode 200 - Step 44567 - Epsilon 0.988920088038167 - Mean Reward 668.37 - Mean Length 234.17 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 943.278 - Time 2024-05-13T17:18:23\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_5.chkpt at step 50000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_6.chkpt at step 60000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_7.chkpt at step 70000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_8.chkpt at step 80000\n",
            "Episode 400 - Step 84364 - Epsilon 0.9791298571137704 - Mean Reward 660.63 - Mean Length 207.38 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 843.923 - Time 2024-05-13T17:32:27\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_9.chkpt at step 90000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_10.chkpt at step 100000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_11.chkpt at step 110000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_12.chkpt at step 120000\n",
            "Episode 600 - Step 124495 - Epsilon 0.9693556041213909 - Mean Reward 654.77 - Mean Length 195.04 - Mean Loss 0.516 - Mean Q Value 5.725 - Time Delta 895.022 - Time 2024-05-13T17:47:22\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_13.chkpt at step 130000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_14.chkpt at step 140000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_15.chkpt at step 150000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_16.chkpt at step 160000\n",
            "Episode 800 - Step 164880 - Epsilon 0.959617985815406 - Mean Reward 610.37 - Mean Length 176.82 - Mean Loss 0.738 - Mean Q Value 15.112 - Time Delta 944.397 - Time 2024-05-13T18:03:06\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_17.chkpt at step 170000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_18.chkpt at step 180000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_19.chkpt at step 190000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_20.chkpt at step 200000\n",
            "Episode 1000 - Step 205125 - Epsilon 0.9500114361405411 - Mean Reward 636.61 - Mean Length 199.18 - Mean Loss 0.856 - Mean Q Value 20.87 - Time Delta 937.16 - Time 2024-05-13T18:18:44\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_21.chkpt at step 210000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_22.chkpt at step 220000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_23.chkpt at step 230000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_24.chkpt at step 240000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_25.chkpt at step 250000\n",
            "Episode 1200 - Step 250952 - Epsilon 0.939189501734872 - Mean Reward 735.27 - Mean Length 256.59 - Mean Loss 1.077 - Mean Q Value 24.545 - Time Delta 1053.425 - Time 2024-05-13T18:36:17\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_26.chkpt at step 260000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_27.chkpt at step 270000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_28.chkpt at step 280000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_29.chkpt at step 290000\n",
            "Episode 1400 - Step 295993 - Epsilon 0.9286733104185346 - Mean Reward 613.4 - Mean Length 189.71 - Mean Loss 1.079 - Mean Q Value 26.201 - Time Delta 1046.092 - Time 2024-05-13T18:53:43\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_30.chkpt at step 300000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_31.chkpt at step 310000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_32.chkpt at step 320000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_33.chkpt at step 330000\n",
            "Episode 1600 - Step 337541 - Epsilon 0.9190771037194051 - Mean Reward 636.34 - Mean Length 184.65 - Mean Loss 1.036 - Mean Q Value 27.228 - Time Delta 966.68 - Time 2024-05-13T19:09:50\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_34.chkpt at step 340000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_35.chkpt at step 350000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_36.chkpt at step 360000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_37.chkpt at step 370000\n",
            "Episode 1800 - Step 377997 - Epsilon 0.9098284062377968 - Mean Reward 714.99 - Mean Length 219.37 - Mean Loss 1.107 - Mean Q Value 29.568 - Time Delta 950.441 - Time 2024-05-13T19:25:40\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_38.chkpt at step 380000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_39.chkpt at step 390000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_40.chkpt at step 400000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_41.chkpt at step 410000\n",
            "Episode 2000 - Step 419998 - Epsilon 0.9003249609187152 - Mean Reward 680.41 - Mean Length 214.86 - Mean Loss 1.161 - Mean Q Value 31.424 - Time Delta 1000.865 - Time 2024-05-13T19:42:21\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_42.chkpt at step 420000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_43.chkpt at step 430000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_44.chkpt at step 440000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_45.chkpt at step 450000\n",
            "Episode 2200 - Step 459942 - Epsilon 0.8913790559833394 - Mean Reward 629.52 - Mean Length 178.47 - Mean Loss 1.16 - Mean Q Value 30.976 - Time Delta 945.037 - Time 2024-05-13T19:58:06\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_46.chkpt at step 460000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_47.chkpt at step 470000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_48.chkpt at step 480000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_49.chkpt at step 490000\n",
            "Episode 2400 - Step 498718 - Epsilon 0.8827797743984154 - Mean Reward 574.92 - Mean Length 190.43 - Mean Loss 1.038 - Mean Q Value 31.686 - Time Delta 930.087 - Time 2024-05-13T20:13:36\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_50.chkpt at step 500000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_51.chkpt at step 510000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_52.chkpt at step 520000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_53.chkpt at step 530000\n",
            "Episode 2600 - Step 538348 - Epsilon 0.8740768161628726 - Mean Reward 638.79 - Mean Length 203.07 - Mean Loss 1.099 - Mean Q Value 32.082 - Time Delta 947.385 - Time 2024-05-13T20:29:24\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_54.chkpt at step 540000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_55.chkpt at step 550000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_56.chkpt at step 560000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_57.chkpt at step 570000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_58.chkpt at step 580000\n",
            "Episode 2800 - Step 580035 - Epsilon 0.8650147085019207 - Mean Reward 703.92 - Mean Length 219.38 - Mean Loss 1.053 - Mean Q Value 31.377 - Time Delta 1011.288 - Time 2024-05-13T20:46:15\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_59.chkpt at step 590000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_60.chkpt at step 600000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_61.chkpt at step 610000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_62.chkpt at step 620000\n",
            "Episode 3000 - Step 621307 - Epsilon 0.8561353728960336 - Mean Reward 601.45 - Mean Length 160.61 - Mean Loss 1.08 - Mean Q Value 31.067 - Time Delta 975.61 - Time 2024-05-13T21:02:31\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_63.chkpt at step 630000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_64.chkpt at step 640000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_65.chkpt at step 650000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_66.chkpt at step 660000\n",
            "Episode 3200 - Step 662378 - Epsilon 0.8473897635267887 - Mean Reward 663.95 - Mean Length 186.33 - Mean Loss 1.019 - Mean Q Value 31.694 - Time Delta 968.589 - Time 2024-05-13T21:18:39\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_67.chkpt at step 670000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_68.chkpt at step 680000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_69.chkpt at step 690000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_70.chkpt at step 700000\n",
            "Episode 3400 - Step 702044 - Epsilon 0.8390281493849314 - Mean Reward 620.85 - Mean Length 192.94 - Mean Loss 1.046 - Mean Q Value 33.564 - Time Delta 947.645 - Time 2024-05-13T21:34:27\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_71.chkpt at step 710000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_72.chkpt at step 720000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_73.chkpt at step 730000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_74.chkpt at step 740000\n",
            "Episode 3600 - Step 740776 - Epsilon 0.8309430460025473 - Mean Reward 640.31 - Mean Length 190.57 - Mean Loss 1.009 - Mean Q Value 33.249 - Time Delta 918.718 - Time 2024-05-13T21:49:46\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_75.chkpt at step 750000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_76.chkpt at step 760000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_77.chkpt at step 770000\n",
            "Episode 3800 - Step 779176 - Epsilon 0.8230041593937413 - Mean Reward 649.54 - Mean Length 200.73 - Mean Loss 1.077 - Mean Q Value 33.54 - Time Delta 908.478 - Time 2024-05-13T22:04:54\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_78.chkpt at step 780000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_79.chkpt at step 790000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_80.chkpt at step 800000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_81.chkpt at step 810000\n",
            "Episode 4000 - Step 819012 - Epsilon 0.8148485382723597 - Mean Reward 621.35 - Mean Length 188.19 - Mean Loss 1.123 - Mean Q Value 33.317 - Time Delta 941.03 - Time 2024-05-13T22:20:35\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_82.chkpt at step 820000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_83.chkpt at step 830000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_84.chkpt at step 840000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_85.chkpt at step 850000\n",
            "Episode 4200 - Step 859829 - Epsilon 0.8065758988642486 - Mean Reward 682.06 - Mean Length 197.62 - Mean Loss 1.062 - Mean Q Value 32.588 - Time Delta 969.592 - Time 2024-05-13T22:36:45\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_86.chkpt at step 860000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_87.chkpt at step 870000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_88.chkpt at step 880000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_89.chkpt at step 890000\n",
            "Episode 4400 - Step 895814 - Epsilon 0.7993522809850433 - Mean Reward 635.33 - Mean Length 187.21 - Mean Loss 1.077 - Mean Q Value 32.999 - Time Delta 853.089 - Time 2024-05-13T22:50:58\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_90.chkpt at step 900000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_91.chkpt at step 910000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_92.chkpt at step 920000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_93.chkpt at step 930000\n",
            "Episode 4600 - Step 937640 - Epsilon 0.791037400851628 - Mean Reward 683.82 - Mean Length 232.58 - Mean Loss 1.052 - Mean Q Value 31.93 - Time Delta 991.669 - Time 2024-05-13T23:07:29\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_94.chkpt at step 940000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_95.chkpt at step 950000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_96.chkpt at step 960000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_97.chkpt at step 970000\n",
            "Episode 4800 - Step 978847 - Epsilon 0.7829301613690187 - Mean Reward 729.34 - Mean Length 213.63 - Mean Loss 1.118 - Mean Q Value 31.867 - Time Delta 977.857 - Time 2024-05-13T23:23:47\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_98.chkpt at step 980000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_99.chkpt at step 990000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_100.chkpt at step 1000000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_101.chkpt at step 1010000\n",
            "Episode 5000 - Step 1015495 - Epsilon 0.7757897146720076 - Mean Reward 698.62 - Mean Length 189.7 - Mean Loss 1.11 - Mean Q Value 32.33 - Time Delta 871.035 - Time 2024-05-13T23:38:18\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_102.chkpt at step 1020000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_103.chkpt at step 1030000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_104.chkpt at step 1040000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_105.chkpt at step 1050000\n",
            "Episode 5200 - Step 1054074 - Epsilon 0.7683433826172833 - Mean Reward 669.24 - Mean Length 194.47 - Mean Loss 1.165 - Mean Q Value 34.868 - Time Delta 919.459 - Time 2024-05-13T23:53:38\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_106.chkpt at step 1060000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_107.chkpt at step 1070000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_108.chkpt at step 1080000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_109.chkpt at step 1090000\n",
            "Episode 5400 - Step 1095191 - Epsilon 0.7604858419183128 - Mean Reward 697.82 - Mean Length 208.26 - Mean Loss 1.136 - Mean Q Value 34.593 - Time Delta 973.038 - Time 2024-05-14T00:09:51\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_110.chkpt at step 1100000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_111.chkpt at step 1110000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_112.chkpt at step 1120000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_113.chkpt at step 1130000\n",
            "Episode 5600 - Step 1133460 - Epsilon 0.7532447766146084 - Mean Reward 718.69 - Mean Length 201.91 - Mean Loss 1.122 - Mean Q Value 34.912 - Time Delta 905.157 - Time 2024-05-14T00:24:56\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_114.chkpt at step 1140000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_115.chkpt at step 1150000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_116.chkpt at step 1160000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_117.chkpt at step 1170000\n",
            "Episode 5800 - Step 1175514 - Epsilon 0.7453670206266233 - Mean Reward 755.09 - Mean Length 219.74 - Mean Loss 1.176 - Mean Q Value 35.581 - Time Delta 996.953 - Time 2024-05-14T00:41:33\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_118.chkpt at step 1180000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_119.chkpt at step 1190000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_120.chkpt at step 1200000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_121.chkpt at step 1210000\n",
            "Episode 6000 - Step 1212096 - Epsilon 0.7385813421975667 - Mean Reward 682.31 - Mean Length 169.12 - Mean Loss 1.233 - Mean Q Value 36.497 - Time Delta 867.357 - Time 2024-05-14T00:56:00\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_122.chkpt at step 1220000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_123.chkpt at step 1230000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_124.chkpt at step 1240000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_125.chkpt at step 1250000\n",
            "Episode 6200 - Step 1253223 - Epsilon 0.7310263384229616 - Mean Reward 791.25 - Mean Length 207.83 - Mean Loss 1.121 - Mean Q Value 37.408 - Time Delta 977.068 - Time 2024-05-14T01:12:17\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_126.chkpt at step 1260000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_127.chkpt at step 1270000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_128.chkpt at step 1280000\n",
            "Episode 6400 - Step 1289310 - Epsilon 0.7244608613106301 - Mean Reward 693.53 - Mean Length 177.0 - Mean Loss 1.156 - Mean Q Value 38.565 - Time Delta 857.816 - Time 2024-05-14T01:26:35\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_129.chkpt at step 1290000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_130.chkpt at step 1300000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_131.chkpt at step 1310000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_132.chkpt at step 1320000\n",
            "Episode 6600 - Step 1325021 - Epsilon 0.7180218408012692 - Mean Reward 688.66 - Mean Length 171.42 - Mean Loss 1.247 - Mean Q Value 38.81 - Time Delta 852.619 - Time 2024-05-14T01:40:48\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_133.chkpt at step 1330000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_134.chkpt at step 1340000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_135.chkpt at step 1350000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_136.chkpt at step 1360000\n",
            "Episode 6800 - Step 1362573 - Epsilon 0.7113125934038307 - Mean Reward 798.08 - Mean Length 192.85 - Mean Loss 1.33 - Mean Q Value 40.299 - Time Delta 901.968 - Time 2024-05-14T01:55:50\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_137.chkpt at step 1370000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_138.chkpt at step 1380000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_139.chkpt at step 1390000\n",
            "Episode 7000 - Step 1399789 - Epsilon 0.7047252321342801 - Mean Reward 755.23 - Mean Length 182.61 - Mean Loss 1.545 - Mean Q Value 41.933 - Time Delta 893.993 - Time 2024-05-14T02:10:44\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_140.chkpt at step 1400000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_141.chkpt at step 1410000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_142.chkpt at step 1420000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_143.chkpt at step 1430000\n",
            "Episode 7200 - Step 1433471 - Epsilon 0.6988160068095438 - Mean Reward 744.95 - Mean Length 176.43 - Mean Loss 1.438 - Mean Q Value 42.926 - Time Delta 811.345 - Time 2024-05-14T02:24:15\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_144.chkpt at step 1440000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_145.chkpt at step 1450000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_146.chkpt at step 1460000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_147.chkpt at step 1470000\n",
            "Episode 7400 - Step 1470405 - Epsilon 0.6923931865948927 - Mean Reward 771.59 - Mean Length 190.07 - Mean Loss 1.43 - Mean Q Value 43.331 - Time Delta 890.216 - Time 2024-05-14T02:39:05\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_148.chkpt at step 1480000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_149.chkpt at step 1490000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_150.chkpt at step 1500000\n",
            "Episode 7600 - Step 1505698 - Epsilon 0.6863108998769373 - Mean Reward 747.79 - Mean Length 173.66 - Mean Loss 1.651 - Mean Q Value 44.087 - Time Delta 849.386 - Time 2024-05-14T02:53:15\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_151.chkpt at step 1510000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_152.chkpt at step 1520000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_153.chkpt at step 1530000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_154.chkpt at step 1540000\n",
            "Episode 7800 - Step 1540780 - Epsilon 0.6803179284731796 - Mean Reward 703.06 - Mean Length 172.9 - Mean Loss 1.685 - Mean Q Value 44.648 - Time Delta 845.822 - Time 2024-05-14T03:07:20\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_155.chkpt at step 1550000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_156.chkpt at step 1560000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_157.chkpt at step 1570000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_158.chkpt at step 1580000\n",
            "Episode 8000 - Step 1580956 - Epsilon 0.6735190156461996 - Mean Reward 777.29 - Mean Length 207.26 - Mean Loss 1.715 - Mean Q Value 44.387 - Time Delta 971.431 - Time 2024-05-14T03:23:32\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_159.chkpt at step 1590000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_160.chkpt at step 1600000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_161.chkpt at step 1610000\n",
            "Episode 8200 - Step 1616446 - Epsilon 0.6675696493400767 - Mean Reward 762.27 - Mean Length 182.41 - Mean Loss 1.849 - Mean Q Value 43.908 - Time Delta 861.014 - Time 2024-05-14T03:37:53\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_162.chkpt at step 1620000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_163.chkpt at step 1630000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_164.chkpt at step 1640000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_165.chkpt at step 1650000\n",
            "Episode 8400 - Step 1651708 - Epsilon 0.6617105517445173 - Mean Reward 738.35 - Mean Length 191.53 - Mean Loss 1.579 - Mean Q Value 43.751 - Time Delta 856.031 - Time 2024-05-14T03:52:09\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_166.chkpt at step 1660000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_167.chkpt at step 1670000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_168.chkpt at step 1680000\n",
            "Episode 8600 - Step 1689150 - Epsilon 0.6555455083124412 - Mean Reward 682.39 - Mean Length 181.33 - Mean Loss 1.59 - Mean Q Value 43.861 - Time Delta 909.613 - Time 2024-05-14T04:07:19\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_169.chkpt at step 1690000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_170.chkpt at step 1700000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_171.chkpt at step 1710000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_172.chkpt at step 1720000\n",
            "Episode 8800 - Step 1727865 - Epsilon 0.6492312527763486 - Mean Reward 690.72 - Mean Length 169.07 - Mean Loss 1.681 - Mean Q Value 41.81 - Time Delta 941.074 - Time 2024-05-14T04:23:00\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_173.chkpt at step 1730000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_174.chkpt at step 1740000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_175.chkpt at step 1750000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_176.chkpt at step 1760000\n",
            "Episode 9000 - Step 1766344 - Epsilon 0.6430157533614738 - Mean Reward 785.19 - Mean Length 202.9 - Mean Loss 1.35 - Mean Q Value 40.639 - Time Delta 939.097 - Time 2024-05-14T04:38:39\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_177.chkpt at step 1770000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_178.chkpt at step 1780000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_179.chkpt at step 1790000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_180.chkpt at step 1800000\n",
            "Episode 9200 - Step 1803454 - Epsilon 0.6370777614178929 - Mean Reward 767.88 - Mean Length 179.04 - Mean Loss 1.324 - Mean Q Value 40.852 - Time Delta 904.807 - Time 2024-05-14T04:53:44\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_181.chkpt at step 1810000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_182.chkpt at step 1820000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_183.chkpt at step 1830000\n",
            "Episode 9400 - Step 1838513 - Epsilon 0.6315183325050451 - Mean Reward 699.32 - Mean Length 179.78 - Mean Loss 1.627 - Mean Q Value 42.031 - Time Delta 855.285 - Time 2024-05-14T05:07:59\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_184.chkpt at step 1840000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_185.chkpt at step 1850000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_186.chkpt at step 1860000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_187.chkpt at step 1870000\n",
            "Episode 9600 - Step 1875085 - Epsilon 0.625770675126707 - Mean Reward 779.18 - Mean Length 181.12 - Mean Loss 1.557 - Mean Q Value 42.275 - Time Delta 895.464 - Time 2024-05-14T05:22:54\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_188.chkpt at step 1880000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_189.chkpt at step 1890000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_190.chkpt at step 1900000\n",
            "Episode 9800 - Step 1907557 - Epsilon 0.6207112322172197 - Mean Reward 732.46 - Mean Length 172.26 - Mean Loss 1.701 - Mean Q Value 43.702 - Time Delta 793.611 - Time 2024-05-14T05:36:08\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_191.chkpt at step 1910000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_192.chkpt at step 1920000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_193.chkpt at step 1930000\n",
            "MarioNet saved to checkpoints/2024-05-13T17-02-37/mario_net_194.chkpt at step 1940000\n",
            "Total number of training episodes completed -  10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize Super Mario environment\n",
        "#env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0', apply_api_compatibility=True, render_mode=\"rgb_array\")\n",
        "\n",
        "# Limit the action-space to\n",
        "#   0. walk right\n",
        "#   1. jump right\n",
        "env = JoypadSpace(\n",
        "    env,\n",
        "    [['right'],\n",
        "    ['right', 'A']]\n",
        ")\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env, keep_dim=False)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = TransformObservation(env, f=lambda x: x / 255.)\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "save_dir = Path('checkpoints') / datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')\n",
        "save_dir.mkdir(parents=True)\n",
        "\n",
        "#####\n",
        "\n",
        "checkpoint_path = '/content/checkpoints/'\n",
        "\n",
        "checkpoint = get_most_recent_checkpoint(checkpoint_path)\n",
        "if checkpoint is not None:\n",
        "  print(f\"\\nLoading checkpoint from {checkpoint}\\n\")\n",
        "  checkpoint = Path(checkpoint)\n",
        "  # gets most recent checkpoint\n",
        "else:\n",
        "  print(\"\\nNo checkpoint found - starting training from zero.\\n\")\n",
        "  checkpoint = None\n",
        "\n",
        "####\n",
        "\n",
        "#checkpoint = None # Path('checkpoints/2020-10-21T18-25-27/mario.chkpt')\n",
        "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir, checkpoint=checkpoint)\n",
        "\n",
        "logger = MetricLogger(save_dir)\n",
        "\n",
        "#episodes = 40000\n",
        "#episodes = 40\n",
        "\n",
        "episodes = 1000\n",
        "record_interval = 200\n",
        "\n",
        "print('Total number of training episodes', Total_num_training_episodes )\n",
        "\n",
        "# Training loop\n",
        "for e in range(episodes):\n",
        "    video = None\n",
        "\n",
        "    if e % record_interval == 0:  # Check if it's time to create a recording\n",
        "        video = cv2.VideoWriter(f'run_4\\mario-rl-{e}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (256,240))\n",
        "\n",
        "    state, info = env.reset()\n",
        "    # Play the game!\n",
        "    while True:\n",
        "        if video is not None:\n",
        "            video.write(cv2.cvtColor(env.render(), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Run agent on the state\n",
        "        action = mario.act(state)\n",
        "\n",
        "        # Agent performs action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        # Remember\n",
        "        mario.cache(state, next_state, action, reward, done)\n",
        "\n",
        "        # Learn\n",
        "        q, loss = mario.learn()\n",
        "\n",
        "        # Logging\n",
        "        logger.log_step(reward, loss, q)\n",
        "\n",
        "        # Update state\n",
        "        state = next_state\n",
        "\n",
        "        # Check if end of game\n",
        "        if done or info['flag_get']:\n",
        "            break\n",
        "\n",
        "    logger.log_episode()\n",
        "    if e % record_interval == 0:\n",
        "        if video is not None:\n",
        "            video.release()\n",
        "\n",
        "        # Log stuff\n",
        "        logger.record(\n",
        "            episode=e,\n",
        "            epsilon=mario.exploration_rate,\n",
        "            step=mario.curr_step\n",
        "        )\n",
        "    Total_num_training_episodes += 1\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}