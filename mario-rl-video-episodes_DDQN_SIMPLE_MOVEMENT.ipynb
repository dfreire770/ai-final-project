{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfreire770/dq-ddq-smb-agent/blob/main/mario-rl-video-episodes_DDQN_SIMPLE_MOVEMENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9zR5l7a-sPne",
        "outputId": "35d734bb-ebf0-48a1-c31d-b6b5d69f7644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827620 sha256=3ca3c62a89f30da5b1f93320a8360a3e91d967cef221ceca4a842caf8afac2ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n",
            "Requirement already satisfied: gym-notices==0.0.8 in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting gym-super-mario-bros==7.4.0\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nes-py>=8.1.4 (from gym-super-mario-bros==7.4.0)\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (1.25.2)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.0.8)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535719 sha256=0ca5961f7d623f86a314d3625447208bb0667092e97d8de703777bb81cd8f0df\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n",
            "Successfully built nes-py\n",
            "Installing collected packages: pyglet, nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.4.0 nes-py-8.2.1 pyglet-1.5.21\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,845 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,083 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,278 kB in 1s (4,093 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev\n",
            "  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libice-dev libopengl-dev libsm-dev libxfont2 libxkbfile1\n",
            "  libxt-dev x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev libxfont2\n",
            "  libxkbfile1 libxt-dev x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 25 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 9,075 kB of archives.\n",
            "After this operation, 18.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 9,075 kB in 2s (4,302 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 25.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../19-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../20-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../21-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../22-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../23-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../24-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.26.2\n",
        "!pip install gym-notices==0.0.8\n",
        "!pip install gymnasium==0.29.1\n",
        "!pip install gym-super-mario-bros==7.4.0\n",
        "!pip install moviepy\n",
        "#!pip install ffmpeg-python==0.2.0\n",
        "\n",
        "#!pip install gym-super-mario-bros\n",
        "!pip --disable-pip-version-check install -q nes_py\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip --disable-pip-version-check install -q pyvirtualdisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zaPSChcvtav4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "\n",
        "import time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# change directory\n",
        "import os\n",
        "# install controller\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "from glob import glob\n",
        "\n",
        "import base64\n",
        "import io\n",
        "\n",
        "import cv2\n",
        "\n",
        "from time import sleep\n",
        "from skimage import transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BkikVdrpuFjN"
      },
      "outputs": [],
      "source": [
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        resize_obs = transform.resize(observation, self.shape)\n",
        "        # cast float back to uint8\n",
        "        resize_obs *= 255\n",
        "        resize_obs = resize_obs.astype(np.uint8)\n",
        "        return resize_obs\n",
        "\n",
        "\n",
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, truncated, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, truncated, info\n",
        "class MarioNet(nn.Module):\n",
        "    \"\"\"\n",
        "        input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        c, w, h = input_dim\n",
        "\n",
        "        if h != 84: raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
        "        if w != 84: raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
        "\n",
        "        self.online = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "\n",
        "        self.target = copy.deepcopy(self.online)\n",
        "\n",
        "        # freeze Q-target parameters\n",
        "        for p in self.target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, input, model):\n",
        "        if model == \"online\":\n",
        "            return self.online(input)\n",
        "        elif model == \"target\":\n",
        "            return self.target(input)\n",
        "\n",
        "\n",
        "class Mario:\n",
        "    def __init__(self, state_dim, action_dim, save_dir, checkpoint=None):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.memory = deque(maxlen=100000)\n",
        "        self.batch_size = 32\n",
        "\n",
        "        self.exploration_rate = 1\n",
        "        self.exploration_rate_decay = 0.99999975\n",
        "        self.exploration_rate_min = 0.1\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        self.curr_step = 0\n",
        "        self.burnin = 1e5  # min. experiences before training\n",
        "        self.learn_every = 3   # no. of experiences between updates to Q_online\n",
        "        self.sync_every = 1e4   # no. of experiences between Q_target & Q_online sync\n",
        "\n",
        "        #self.save_every = 5e5   # no. of experiences between saving Mario Net\n",
        "        self.save_every = 10000\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "\n",
        "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
        "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
        "        if self.use_cuda:\n",
        "            self.net = self.net.to(device='cuda')\n",
        "        if checkpoint:\n",
        "            self.load(checkpoint)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
        "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Given a state, choose an epsilon-greedy action and update value of step.\n",
        "\n",
        "        Inputs:\n",
        "        state(LazyFrame): A single observation of the current state, dimension is (state_dim)\n",
        "        Outputs:\n",
        "        action_idx (int): An integer representing which action Mario will perform\n",
        "        \"\"\"\n",
        "        # EXPLORE\n",
        "        if np.random.rand() < self.exploration_rate:\n",
        "            action_idx = np.random.randint(self.action_dim)\n",
        "\n",
        "        # EXPLOIT\n",
        "        else:\n",
        "            state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n",
        "            state = state.unsqueeze(0)\n",
        "            action_values = self.net(state, model='online')\n",
        "            action_idx = torch.argmax(action_values, axis=1).item()\n",
        "\n",
        "        # decrease exploration_rate\n",
        "        self.exploration_rate *= self.exploration_rate_decay\n",
        "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
        "\n",
        "        # increment step\n",
        "        self.curr_step += 1\n",
        "        return action_idx\n",
        "\n",
        "    def cache(self, state, next_state, action, reward, done):\n",
        "        \"\"\"\n",
        "        Store the experience to self.memory (replay buffer)\n",
        "\n",
        "        Inputs:\n",
        "        state (LazyFrame),\n",
        "        next_state (LazyFrame),\n",
        "        action (int),\n",
        "        reward (float),\n",
        "        done(bool))\n",
        "        \"\"\"\n",
        "        state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n",
        "        next_state = torch.FloatTensor(next_state).cuda() if self.use_cuda else torch.FloatTensor(next_state)\n",
        "        action = torch.LongTensor([action]).cuda() if self.use_cuda else torch.LongTensor([action])\n",
        "        reward = torch.DoubleTensor([reward]).cuda() if self.use_cuda else torch.DoubleTensor([reward])\n",
        "        done = torch.BoolTensor([done]).cuda() if self.use_cuda else torch.BoolTensor([done])\n",
        "\n",
        "        self.memory.append( (state, next_state, action, reward, done,) )\n",
        "\n",
        "\n",
        "    def recall(self):\n",
        "        \"\"\"\n",
        "        Retrieve a batch of experiences from memory\n",
        "        \"\"\"\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        state, next_state, action, reward, done = map(torch.stack, zip(*batch))\n",
        "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
        "\n",
        "\n",
        "    def td_estimate(self, state, action):\n",
        "        current_Q = self.net(state, model='online')[np.arange(0, self.batch_size), action] # Q_online(s,a)\n",
        "        return current_Q\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def td_target(self, reward, next_state, done):\n",
        "        next_state_Q = self.net(next_state, model='online')\n",
        "        best_action = torch.argmax(next_state_Q, axis=1)\n",
        "        next_Q = self.net(next_state, model='target')[np.arange(0, self.batch_size), best_action]\n",
        "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()\n",
        "\n",
        "\n",
        "    def update_Q_online(self, td_estimate, td_target) :\n",
        "        loss = self.loss_fn(td_estimate, td_target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def sync_Q_target(self):\n",
        "        self.net.target.load_state_dict(self.net.online.state_dict())\n",
        "\n",
        "\n",
        "    def learn(self):\n",
        "        if self.curr_step % self.sync_every == 0:\n",
        "            self.sync_Q_target()\n",
        "\n",
        "        if self.curr_step % self.save_every == 0:\n",
        "            self.save()\n",
        "\n",
        "        if self.curr_step < self.burnin:\n",
        "            return None, None\n",
        "\n",
        "        if self.curr_step % self.learn_every != 0:\n",
        "            return None, None\n",
        "\n",
        "        # Sample from memory\n",
        "        state, next_state, action, reward, done = self.recall()\n",
        "\n",
        "        # Get TD Estimate\n",
        "        td_est = self.td_estimate(state, action)\n",
        "\n",
        "        # Get TD Target\n",
        "        td_tgt = self.td_target(reward, next_state, done)\n",
        "\n",
        "        # Backpropagate loss through Q_online\n",
        "        loss = self.update_Q_online(td_est, td_tgt)\n",
        "\n",
        "        return (td_est.mean().item(), loss)\n",
        "\n",
        "\n",
        "    def save(self):\n",
        "        save_path = self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
        "        torch.save(\n",
        "            dict(\n",
        "                model=self.net.state_dict(),\n",
        "                exploration_rate=self.exploration_rate\n",
        "            ),\n",
        "            save_path\n",
        "        )\n",
        "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
        "\n",
        "\n",
        "    def load(self, load_path):\n",
        "        if not load_path.exists():\n",
        "            raise ValueError(f\"{load_path} does not exist\")\n",
        "\n",
        "        ckp = torch.load(load_path, map_location=('cuda' if self.use_cuda else 'cpu'))\n",
        "        exploration_rate = ckp.get('exploration_rate')\n",
        "        state_dict = ckp.get('model')\n",
        "\n",
        "        print(f\"Loading model at {load_path} with exploration rate {exploration_rate}\")\n",
        "        self.net.load_state_dict(state_dict)\n",
        "        self.exploration_rate = exploration_rate\n",
        "\n",
        "class MetricLogger():\n",
        "    def __init__(self, save_dir):\n",
        "        self.save_log = save_dir / \"log\"\n",
        "        with open(self.save_log, \"w\") as f:\n",
        "            f.write(\n",
        "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
        "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
        "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
        "            )\n",
        "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
        "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
        "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
        "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
        "\n",
        "        # History metrics\n",
        "        self.ep_rewards = []\n",
        "        self.ep_lengths = []\n",
        "        self.ep_avg_losses = []\n",
        "        self.ep_avg_qs = []\n",
        "\n",
        "        # Moving averages, added for every call to record()\n",
        "        self.moving_avg_ep_rewards = []\n",
        "        self.moving_avg_ep_lengths = []\n",
        "        self.moving_avg_ep_avg_losses = []\n",
        "        self.moving_avg_ep_avg_qs = []\n",
        "\n",
        "        # Current episode metric\n",
        "        self.init_episode()\n",
        "\n",
        "        # Timing\n",
        "        self.record_time = time.time()\n",
        "\n",
        "\n",
        "    def log_step(self, reward, loss, q):\n",
        "        self.curr_ep_reward += reward\n",
        "        self.curr_ep_length += 1\n",
        "        if loss:\n",
        "            self.curr_ep_loss += loss\n",
        "            self.curr_ep_q += q\n",
        "            self.curr_ep_loss_length += 1\n",
        "\n",
        "    def log_episode(self):\n",
        "        \"Mark end of episode\"\n",
        "        self.ep_rewards.append(self.curr_ep_reward)\n",
        "        self.ep_lengths.append(self.curr_ep_length)\n",
        "        if self.curr_ep_loss_length == 0:\n",
        "            ep_avg_loss = 0\n",
        "            ep_avg_q = 0\n",
        "        else:\n",
        "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
        "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
        "        self.ep_avg_losses.append(ep_avg_loss)\n",
        "        self.ep_avg_qs.append(ep_avg_q)\n",
        "\n",
        "        self.init_episode()\n",
        "\n",
        "    def init_episode(self):\n",
        "        self.curr_ep_reward = 0.0\n",
        "        self.curr_ep_length = 0\n",
        "        self.curr_ep_loss = 0.0\n",
        "        self.curr_ep_q = 0.0\n",
        "        self.curr_ep_loss_length = 0\n",
        "\n",
        "    def record(self, episode, epsilon, step):\n",
        "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
        "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
        "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
        "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
        "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
        "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
        "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
        "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
        "        last_record_time = self.record_time\n",
        "        self.record_time = time.time()\n",
        "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
        "\n",
        "        print(\n",
        "            f\"Episode {episode} - \"\n",
        "            f\"Step {step} - \"\n",
        "            f\"Epsilon {epsilon} - \"\n",
        "            f\"Mean Reward {mean_ep_reward} - \"\n",
        "            f\"Mean Length {mean_ep_length} - \"\n",
        "            f\"Mean Loss {mean_ep_loss} - \"\n",
        "            f\"Mean Q Value {mean_ep_q} - \"\n",
        "            f\"Time Delta {time_since_last_record} - \"\n",
        "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
        "        )\n",
        "\n",
        "        with open(self.save_log, \"a\") as f:\n",
        "            f.write(\n",
        "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
        "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
        "                f\"{time_since_last_record:15.3f}\"\n",
        "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
        "            )\n",
        "\n",
        "        for metric in [\"ep_rewards\", \"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\"]:\n",
        "            plt.plot(getattr(self, f\"moving_avg_{metric}\"))\n",
        "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n",
        "            plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_recent_checkpoint(path):\n",
        "\n",
        "  if os.path.exists(path):\n",
        "    # Get a list of all files in the directory\n",
        "    file_list = []\n",
        "    for file in glob(f'{path}/*/*.chkpt'):\n",
        "      file_list.append(file)\n",
        "    file_list.sort(key=os.path.getmtime)\n",
        "    if len(file_list) > 0:\n",
        "      return file_list[-1]\n",
        "    else:\n",
        "      return None\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "Total_num_training_episodes = 0\n",
        "# initial number of total episodes training"
      ],
      "metadata": {
        "id": "YViGcbSrQOgM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### MANUAL RETRIEVAL CODE FOR WHEN RUNTIME CRASHED AFTER 10,000 EPISODES\n",
        "\n",
        "#Total_num_training_episodes = 20000\n",
        "#save_dir = Path('checkpoints') / datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')\n",
        "#save_dir.mkdir(parents=True)\n",
        "\n",
        "#### MANUAL RETRIEVAL CODE FOR WHEN RUNTIME CRASHED AFTER 10,000 EPISODES"
      ],
      "metadata": {
        "id": "lNTyoTReTpE1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjzuPvNkuVbk",
        "outputId": "c17ed962-1387-4547-b1dd-7fc5623f4054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No checkpoint found - starting training from zero.\n",
            "\n",
            "Total number of training episodes 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "<ipython-input-3-5ed268c1874b>:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  state = torch.FloatTensor(state).cuda() if self.use_cuda else torch.FloatTensor(state)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 - Step 63 - Epsilon 0.9999842501220597 - Mean Reward 217.0 - Mean Length 63.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 1.506 - Time 2024-05-15T15:14:00\n"
          ]
        }
      ],
      "source": [
        "# Initialize Super Mario environment\n",
        "#env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0', apply_api_compatibility=True, render_mode=\"rgb_array\")\n",
        "\n",
        "# Limit the action-space to\n",
        "#   0. walk right\n",
        "#   1. jump right\n",
        "env = JoypadSpace(\n",
        "    env, SIMPLE_MOVEMENT\n",
        ")\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env, keep_dim=False)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = TransformObservation(env, f=lambda x: x / 255.)\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "save_dir = Path('checkpoints') / datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')\n",
        "save_dir.mkdir(parents=True)\n",
        "\n",
        "#####\n",
        "\n",
        "checkpoint_path = '/content/checkpoints/'\n",
        "\n",
        "checkpoint = get_most_recent_checkpoint(checkpoint_path)\n",
        "if checkpoint is not None:\n",
        "  print(f\"\\nLoading checkpoint from {checkpoint}\\n\")\n",
        "  checkpoint = Path(checkpoint)\n",
        "  # gets most recent checkpoint\n",
        "else:\n",
        "  print(\"\\nNo checkpoint found - starting training from zero.\\n\")\n",
        "  checkpoint = None\n",
        "\n",
        "####\n",
        "\n",
        "#checkpoint = None # Path('checkpoints/2020-10-21T18-25-27/mario.chkpt')\n",
        "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir, checkpoint=checkpoint)\n",
        "\n",
        "logger = MetricLogger(save_dir)\n",
        "\n",
        "#episodes = 40000\n",
        "#episodes = 40\n",
        "\n",
        "episodes = 10000\n",
        "record_interval = 200\n",
        "\n",
        "print('Total number of training episodes', Total_num_training_episodes )\n",
        "\n",
        "# Training loop\n",
        "for e in range(episodes):\n",
        "    video = None\n",
        "\n",
        "    if e % record_interval == 0:  # Check if it's time to create a recording\n",
        "        video = cv2.VideoWriter(f'mario-rl-{Total_num_training_episodes}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (256,240))\n",
        "\n",
        "    state, info = env.reset()\n",
        "    # Play the game!\n",
        "    while True:\n",
        "        if video is not None:\n",
        "            video.write(cv2.cvtColor(env.render(), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Run agent on the state\n",
        "        action = mario.act(state)\n",
        "\n",
        "        # Agent performs action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        # Remember\n",
        "        mario.cache(state, next_state, action, reward, done)\n",
        "\n",
        "        # Learn\n",
        "        q, loss = mario.learn()\n",
        "\n",
        "        # Logging\n",
        "        logger.log_step(reward, loss, q)\n",
        "\n",
        "        # Update state\n",
        "        state = next_state\n",
        "\n",
        "        # Check if end of game\n",
        "        if done or info['flag_get']:\n",
        "            break\n",
        "\n",
        "    logger.log_episode()\n",
        "    if e % record_interval == 0:\n",
        "        if video is not None:\n",
        "            video.release()\n",
        "\n",
        "        # Log stuff\n",
        "        logger.record(\n",
        "            episode=e,\n",
        "            epsilon=mario.exploration_rate,\n",
        "            step=mario.curr_step\n",
        "        )\n",
        "    Total_num_training_episodes += 1\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}